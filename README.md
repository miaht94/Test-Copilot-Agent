# Trino + DBT + Iceberg Data Pipeline

A complete end-to-end data pipeline template that demonstrates modern data lake architecture using Trino, DBT, and Apache Iceberg with S3-compatible storage (Minio).

## ğŸ—ï¸ Architecture Overview

This pipeline demonstrates:

1. **Data Ingestion**: From PostgreSQL source database
2. **Data Transformation**: Using DBT models with SQL-based transformations
3. **Query Engine**: Trino for distributed SQL queries across multiple data sources
4. **Data Storage**: Apache Iceberg tables stored on Minio (S3A protocol)
5. **Data Catalog**: Hive Metastore for table metadata management

## ğŸ”§ Components

- **PostgreSQL**: Source database with sample e-commerce data
- **Trino**: Distributed SQL query engine
- **DBT**: Data transformation tool with SQL models
- **Apache Iceberg**: Table format for large analytic datasets
- **Minio**: S3-compatible object storage
- **Hive Metastore**: Metadata management for Iceberg tables

## ğŸš€ Quick Start

### Prerequisites

- Docker and Docker Compose
- At least 8GB RAM available for containers
- Ports 5432, 5433, 8080, 9000, 9001, 9083 available

### Setup

1. Clone this repository:
```bash
git clone <repository-url>
cd Test-Copilot-Agent
```

2. Run the setup script:
```bash
./setup.sh
```

This script will:
- Start all required services using Docker Compose
- Initialize sample data in PostgreSQL
- Set up Iceberg schemas in Trino
- Run DBT transformations
- Verify the pipeline is working

### Manual Setup (Alternative)

If you prefer manual setup:

```bash
# Start services
docker-compose up -d

# Wait for services to be ready (about 60 seconds)
sleep 60

# Create Iceberg schemas
docker exec trino trino --execute "CREATE SCHEMA IF NOT EXISTS iceberg.staging"
docker exec trino trino --execute "CREATE SCHEMA IF NOT EXISTS iceberg.marts"

# Run DBT transformations
docker exec dbt dbt run
docker exec dbt dbt test
```

## ğŸ“Š Sample Data

The pipeline includes sample e-commerce data:

- **Customers**: 10 sample customers with contact information
- **Products**: 10 sample products across electronics and accessories
- **Orders**: 10 sample orders with various statuses
- **Order Items**: Detailed line items for each order

## ğŸ” Data Models

### Staging Models (`staging/`)
- `stg_customers`: Clean customer data from source
- `stg_products`: Clean product data from source  
- `stg_orders`: Clean order data from source
- `stg_order_items`: Clean order item data from source

### Mart Models (`marts/`)
- `dim_customers`: Customer dimension table
- `dim_products`: Product dimension table with calculated metrics
- `fact_sales`: Sales fact table with order and profit calculations
- `customer_analytics`: Customer aggregated analytics
- `product_analytics`: Product performance analytics

## ğŸŒ Access Points

After running setup:

- **Trino UI**: http://localhost:8080
- **Minio Console**: http://localhost:9001 (login: minioadmin/minioadmin)
- **PostgreSQL**: localhost:5432 (postgres/postgres)

## ğŸ“ Usage Examples

### Connect to Trino CLI
```bash
docker exec -it trino trino
```

### Query Cross-Catalog Data
```sql
-- Query source data
SELECT * FROM postgres.sales.customers LIMIT 5;

-- Query transformed data
SELECT * FROM iceberg.marts.customer_analytics LIMIT 5;

-- Cross-catalog join
SELECT 
    p.product_name,
    pa.total_revenue
FROM postgres.sales.products p
JOIN iceberg.marts.product_analytics pa ON p.product_id = pa.product_id;
```

### Run DBT Commands
```bash
# Connect to DBT container
docker exec -it dbt bash

# Run all models
dbt run

# Run specific model
dbt run --models fact_sales

# Run tests
dbt test

# Generate documentation
dbt docs generate
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ docker-compose.yml          # Container orchestration
â”œâ”€â”€ setup.sh                    # Automated setup script
â”œâ”€â”€ stop.sh                     # Clean shutdown script
â”œâ”€â”€ init-scripts/               # PostgreSQL initialization
â”‚   â””â”€â”€ 01-init-sample-data.sql
â”œâ”€â”€ trino-config/               # Trino configuration
â”‚   â”œâ”€â”€ config.properties
â”‚   â”œâ”€â”€ node.properties
â”‚   â””â”€â”€ catalog/
â”‚       â”œâ”€â”€ postgres.properties
â”‚       â””â”€â”€ iceberg.properties
â”œâ”€â”€ hive-config/                # Hive Metastore configuration
â”‚   â””â”€â”€ hive-site.xml
â”œâ”€â”€ dbt/                        # DBT project
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ profiles.yml
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â””â”€â”€ marts/
â”‚   â””â”€â”€ Dockerfile
â””â”€â”€ examples/                   # Usage examples
    â”œâ”€â”€ sample_queries.sql
    â””â”€â”€ dbt_commands.md
```

## ğŸ§ª Testing the Pipeline

### Verify Source Data
```bash
docker exec postgres psql -U postgres -d sourcedb -c "SELECT COUNT(*) FROM sales.customers;"
```

### Verify Transformed Data
```bash
docker exec trino trino --execute "SELECT COUNT(*) FROM iceberg.marts.fact_sales;"
```

### Run Analytics Queries
```bash
docker exec trino trino --execute "SELECT customer_name, total_revenue FROM iceberg.marts.customer_analytics ORDER BY total_revenue DESC LIMIT 5;"
```

## ğŸ› ï¸ Customization

### Adding New Source Tables
1. Add tables to PostgreSQL init script
2. Create staging models in `dbt/models/staging/`
3. Update `_sources.yml` with new table definitions
4. Create or update mart models as needed

### Adding New Transformations
1. Create new DBT models in appropriate folder
2. Update `dbt_project.yml` if needed
3. Run `dbt run` to execute

### Configuring Storage
- Modify Minio settings in `docker-compose.yml`
- Update S3 credentials in `hive-config/hive-site.xml`
- Adjust Trino catalog properties as needed

## ğŸ› Troubleshooting

### Services Not Starting
```bash
# Check service status
docker-compose ps

# View logs
docker-compose logs trino
docker-compose logs dbt
```

### Connection Issues
```bash
# Test Trino connectivity
curl http://localhost:8080/v1/info

# Test PostgreSQL connectivity
docker exec postgres pg_isready -U postgres
```

### DBT Issues
```bash
# Debug DBT configuration
docker exec dbt dbt debug

# Check compiled SQL
docker exec dbt dbt compile
```

## ğŸ“š Additional Resources

- [Trino Documentation](https://trino.io/docs/)
- [DBT Documentation](https://docs.getdbt.com/)
- [Apache Iceberg Documentation](https://iceberg.apache.org/docs/)
- [Minio Documentation](https://docs.min.io/)

## ğŸ›‘ Cleanup

To stop all services and clean up:

```bash
./stop.sh

# Or manually:
docker-compose down

# To remove all data volumes:
docker-compose down -v
```

## ğŸ“„ License

This project is provided as-is for educational and demonstration purposes.
